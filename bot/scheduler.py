import logging
from datetime import datetime, time, timedelta
import os
import asyncio
import json

from aiogram import Bot
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.date import DateTrigger
from redis.asyncio.client import Redis

from bot.tasks import send_lesson_reminder_task, send_message_task
from bot.text_formatters import (
    format_schedule_text, generate_evening_intro, generate_morning_intro, get_footer_with_promo
)
from core.config import (
    CHECK_INTERVAL_MINUTES, MOSCOW_TZ, OPENWEATHERMAP_API_KEY,
    OPENWEATHERMAP_CITY_ID, OPENWEATHERMAP_UNITS, REDIS_SCHEDULE_HASH_KEY
)
from core.manager import TimetableManager
from core.metrics import SUBSCRIBED_USERS, TASKS_SENT_TO_QUEUE, USERS_TOTAL, LAST_SCHEDULE_UPDATE_TS, ERRORS_TOTAL
from core.parser import fetch_and_parse_all_schedules
from datetime import datetime as _dt
from core.user_data import UserDataManager
from core.weather_api import WeatherAPI
from core.image_cache_manager import ImageCacheManager
from core.image_generator import generate_schedule_image
from aiogram.types import CallbackQuery

logger = logging.getLogger(__name__)

def print_progress_bar(current: int, total: int, prefix: str = "–ü—Ä–æ–≥—Ä–µ—Å—Å", suffix: str = "", length: int = 50):
    """
    –í—ã–≤–æ–¥–∏—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –≤ –∫–æ–Ω—Å–æ–ª—å.
    
    Args:
        current: –¢–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        total: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        prefix: –ü—Ä–µ—Ñ–∏–∫—Å —Å–æ–æ–±—â–µ–Ω–∏—è
        suffix: –°—É—Ñ—Ñ–∏–∫—Å —Å–æ–æ–±—â–µ–Ω–∏—è
        length: –î–ª–∏–Ω–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
    """
    filled_length = int(length * current // total)
    bar = '‚ñà' * filled_length + '-' * (length - filled_length)
    percent = f"{100 * current // total}%"
    print(f'\r{prefix} |{bar}| {percent} {suffix}', end='', flush=True)
    if current == total:
        print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ –∫–æ–Ω—Ü–µ

async def evening_broadcast(user_data_manager: UserDataManager, timetable_manager: TimetableManager):
    tomorrow = datetime.now(MOSCOW_TZ) + timedelta(days=1)
    logger.info(f"–ù–∞—á–∏–Ω–∞—é –ø–æ—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–¥–∞—á –Ω–∞ –≤–µ—á–µ—Ä–Ω—é—é —Ä–∞—Å—Å—ã–ª–∫—É –¥–ª—è –¥–∞—Ç—ã {tomorrow.date().isoformat()}")
    
    weather_api = WeatherAPI(OPENWEATHERMAP_API_KEY, OPENWEATHERMAP_CITY_ID, OPENWEATHERMAP_UNITS)
    tomorrow_9am = MOSCOW_TZ.localize(datetime.combine(tomorrow.date(), time(9, 0)))
    weather_forecast = await weather_api.get_forecast_for_time(tomorrow_9am)
    intro_text = generate_evening_intro(weather_forecast, target_date=tomorrow)
    
    users_to_notify = await user_data_manager.get_users_for_evening_notify()
    if not users_to_notify:
        logger.info("–í–µ—á–µ—Ä–Ω—è—è —Ä–∞—Å—Å—ã–ª–∫–∞: –Ω–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è.")
        return

    for user_id, group_name in users_to_notify:
        schedule_info = await timetable_manager.get_schedule_for_day(group_name, target_date=tomorrow.date())
        has_lessons = bool(schedule_info and not schedule_info.get('error') and schedule_info.get('lessons'))
        
        text_body = f"<b>–í–∞—à–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –∑–∞–≤—Ç—Ä–∞:</b>\n\n{format_schedule_text(schedule_info)}" if has_lessons else "üéâ <b>–ó–∞–≤—Ç—Ä–∞ –∑–∞–Ω—è—Ç–∏–π –Ω–µ—Ç!</b>"
        text = f"{intro_text}{text_body}{get_footer_with_promo()}"
        
        send_message_task.send(user_id, text)
        TASKS_SENT_TO_QUEUE.labels(actor_name='send_message_task').inc()

async def morning_summary_broadcast(user_data_manager: UserDataManager, timetable_manager: TimetableManager):
    today = datetime.now(MOSCOW_TZ)
    logger.info(f"–ù–∞—á–∏–Ω–∞—é –ø–æ—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–¥–∞—á –Ω–∞ —É—Ç—Ä–µ–Ω–Ω—é—é —Ä–∞—Å—Å—ã–ª–∫—É –¥–ª—è –¥–∞—Ç—ã {today.date().isoformat()}")

    weather_api = WeatherAPI(OPENWEATHERMAP_API_KEY, OPENWEATHERMAP_CITY_ID, OPENWEATHERMAP_UNITS)
    today_9am = MOSCOW_TZ.localize(datetime.combine(today.date(), time(9, 0)))
    weather_forecast = await weather_api.get_forecast_for_time(today_9am)
    intro_text = generate_morning_intro(weather_forecast)
    
    users_to_notify = await user_data_manager.get_users_for_morning_summary()
    if not users_to_notify:
        logger.info("–£—Ç—Ä–µ–Ω–Ω—è—è —Ä–∞—Å—Å—ã–ª–∫–∞: –Ω–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è.")
        return

    for user_id, group_name in users_to_notify:
        schedule_info = await timetable_manager.get_schedule_for_day(group_name, target_date=today.date())
        if schedule_info and not schedule_info.get('error') and schedule_info.get('lessons'):
            text = f"{intro_text}\n<b>–í–∞—à–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è:</b>\n\n{format_schedule_text(schedule_info)}{get_footer_with_promo()}"
            send_message_task.send(user_id, text)
            TASKS_SENT_TO_QUEUE.labels(actor_name='send_message_task').inc()

async def lesson_reminders_planner(scheduler: AsyncIOScheduler, user_data_manager: UserDataManager, timetable_manager: TimetableManager):
    now_in_moscow = datetime.now(MOSCOW_TZ)
    today = now_in_moscow.date()
    logger.info(f"–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ –ø–∞—Ä–∞—Ö –¥–ª—è –¥–∞—Ç—ã {today.isoformat()}")

    users_to_plan = await user_data_manager.get_users_for_lesson_reminders()
    if not users_to_plan:
        return

    for user_id, group_name, reminder_time in users_to_plan:
        schedule_info = await timetable_manager.get_schedule_for_day(group_name, target_date=today)
        if not (schedule_info and not schedule_info.get('error') and schedule_info.get('lessons')):
            continue
        
        try:
            lessons = sorted(schedule_info['lessons'], key=lambda x: datetime.strptime(x['start_time_raw'], '%H:%M').time())
        except (ValueError, KeyError):
            continue
        
        if lessons:
            try:
                start_time_obj = datetime.strptime(lessons[0]['start_time_raw'], '%H:%M').time()
                start_dt = MOSCOW_TZ.localize(datetime.combine(today, start_time_obj))
                reminder_dt = start_dt - timedelta(minutes=reminder_time)
                
                # –ü–ª–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ–≥–¥–∞: –µ—Å–ª–∏ –≤—Ä–µ–º—è –ø—Ä–æ—à–ª–æ, —Å—Ç–∞–≤–∏–º –Ω–∞ –±–ª–∏–∂–∞–π—à—É—é —Å–µ–∫—É–Ω–¥—É
                run_at = reminder_dt if reminder_dt >= now_in_moscow else now_in_moscow + timedelta(seconds=1)
                scheduler.add_job(
                    send_lesson_reminder_task.send,
                    trigger=DateTrigger(run_date=run_at),
                    args=(user_id, lessons[0], "first", None, reminder_time),
                    id=f"reminder_{user_id}_{today.isoformat()}_first",
                    replace_existing=True,
                )
            except (ValueError, KeyError) as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –ø–µ—Ä–≤–æ–π –ø–∞—Ä–µ –¥–ª—è user_id={user_id}: {e}")

        for i, lesson in enumerate(lessons):
            try:
                end_time_obj = datetime.strptime(lesson['end_time_raw'], '%H:%M').time()
                reminder_dt = MOSCOW_TZ.localize(datetime.combine(today, end_time_obj))
                
                run_at = reminder_dt if reminder_dt >= now_in_moscow else now_in_moscow + timedelta(seconds=1)
                is_last_lesson = (i == len(lessons) - 1)
                reminder_type = "final" if is_last_lesson else "break"
                next_lesson = lessons[i+1] if not is_last_lesson else None
                break_duration = None
                if next_lesson:
                    next_start_time_obj = datetime.strptime(next_lesson['start_time_raw'], '%H:%M').time()
                    break_duration = int((datetime.combine(today, next_start_time_obj) - datetime.combine(today, end_time_obj)).total_seconds() / 60)
                
                scheduler.add_job(
                    send_lesson_reminder_task.send,
                    trigger=DateTrigger(run_date=run_at),
                    args=(user_id, next_lesson, reminder_type, break_duration, None),
                    id=f"reminder_{user_id}_{today.isoformat()}_{lesson['end_time_raw']}",
                    replace_existing=True,
                )
            except (ValueError, KeyError) as e:
                 logger.warning(f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ –ø–µ—Ä–µ—Ä—ã–≤–µ –¥–ª—è user_id={user_id}: {e}")

async def cancel_reminders_for_user(scheduler: AsyncIOScheduler, user_id: int):
    try:
        now_in_moscow = datetime.now(MOSCOW_TZ)
        today_iso = now_in_moscow.date().isoformat()
        for job in list(scheduler.get_jobs()):
            if job.id and job.id.startswith(f"reminder_{user_id}_{today_iso}"):
                try:
                    scheduler.remove_job(job.id)
                except Exception:
                    pass
    except Exception as e:
        logger.warning(f"cancel_reminders_for_user failed for {user_id}: {e}")

async def plan_reminders_for_user(scheduler: AsyncIOScheduler, user_data_manager: UserDataManager, timetable_manager: TimetableManager, user_id: int):
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≥—Ä—É–ø–ø—É –∏ –≤—Ä–µ–º—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
        user = await user_data_manager.get_full_user_info(user_id)
        if not user or not user.group or not user.lesson_reminders:
            return
        today = datetime.now(MOSCOW_TZ).date()
        schedule_info = await timetable_manager.get_schedule_for_day(user.group, target_date=today)
        if not (schedule_info and not schedule_info.get('error') and schedule_info.get('lessons')):
            return
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–∞—Ä—ã
        try:
            lessons = sorted(schedule_info['lessons'], key=lambda x: datetime.strptime(x['start_time_raw'], '%H:%M').time())
        except (ValueError, KeyError):
            return
        now_in_moscow = datetime.now(MOSCOW_TZ)
        # –ü–µ—Ä–≤–∞—è –ø–∞—Ä–∞ —Å —É—á—ë—Ç–æ–º –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
        if lessons:
            try:
                start_time_obj = datetime.strptime(lessons[0]['start_time_raw'], '%H:%M').time()
                start_dt = MOSCOW_TZ.localize(datetime.combine(today, start_time_obj))
                reminder_dt = start_dt - timedelta(minutes=(user.reminder_time_minutes or 20))
                run_at = reminder_dt if reminder_dt >= now_in_moscow else now_in_moscow + timedelta(seconds=1)
                scheduler.add_job(
                    send_lesson_reminder_task.send,
                    trigger=DateTrigger(run_date=run_at),
                    args=(user_id, lessons[0], "first", None, user.reminder_time_minutes),
                    id=f"reminder_{user_id}_{today.isoformat()}_first",
                    replace_existing=True,
                )
            except Exception:
                pass
        # –ü–µ—Ä–µ—Ä—ã–≤—ã/–∫–æ–Ω–µ—Ü
        for i, lesson in enumerate(lessons):
            try:
                end_time_obj = datetime.strptime(lesson['end_time_raw'], '%H:%M').time()
                reminder_dt = MOSCOW_TZ.localize(datetime.combine(today, end_time_obj))
                run_at = reminder_dt if reminder_dt >= now_in_moscow else now_in_moscow + timedelta(seconds=1)
                is_last = (i == len(lessons) - 1)
                next_lesson = lessons[i+1] if not is_last else None
                break_duration = None
                if next_lesson:
                    next_start_time_obj = datetime.strptime(next_lesson['start_time_raw'], '%H:%M').time()
                    break_duration = int((datetime.combine(today, next_start_time_obj) - datetime.combine(today, end_time_obj)).total_seconds() / 60)
                scheduler.add_job(
                    send_lesson_reminder_task.send,
                    trigger=DateTrigger(run_date=run_at),
                    args=(user_id, next_lesson, ("final" if is_last else "break"), break_duration, None),
                    id=f"reminder_{user_id}_{today.isoformat()}_{lesson['end_time_raw']}",
                    replace_existing=True,
                )
            except Exception:
                continue
    except Exception as e:
        logger.warning(f"plan_reminders_for_user failed for {user_id}: {e}")

async def warm_top_groups_images(user_data_manager: UserDataManager, timetable_manager: TimetableManager, redis_client: Redis):
    try:
        cache = ImageCacheManager(redis_client, cache_ttl_hours=24)
        # –¢–æ–ø-10 –≥—Ä—É–ø–ø –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
        try:
            top = await user_data_manager.get_top_groups(limit=10)
            top_groups = [g for g, _ in top if g]
        except Exception:
            top_groups = []
        # –ï—Å–ª–∏ –ë–î –Ω–µ –¥–∞–ª–∞ —Ç–æ–ø, –≤–æ–∑—å–º—ë–º –ø–µ—Ä–≤—ã–µ 10 –∫–ª—é—á–µ–π —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π
        if not top_groups:
            top_groups = list(k for k in timetable_manager._schedules.keys())[:10]
        if not top_groups:
            return
        today = datetime.now(MOSCOW_TZ).date()
        week_key_name = timetable_manager.get_week_type(today)
        if not week_key_name:
            return
        week_key, week_name = week_key_name
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        groups_to_generate = []
        for group in top_groups:
            cache_key = f"{group}_{week_key}"
            if await cache.is_cached(cache_key):
                continue
            # Redis-–ª–æ–∫ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª—é—á–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            gen_lock_key = f"image_gen_lock:warm:{cache_key}"
            lock_acquired = False
            try:
                lock_acquired = await redis_client.set(gen_lock_key, "1", nx=True, ex=120)
            except Exception:
                pass
            if not lock_acquired:
                continue
            full_schedule = timetable_manager._schedules.get(group.upper(), {})
            week_schedule = full_schedule.get(week_key, {})
            # –ü—É—Ç—å –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            from core.config import MEDIA_PATH
            output_dir = MEDIA_PATH / "generated"
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = output_dir / f"{cache_key}.png"
            groups_to_generate.append((cache_key, week_schedule, week_name, group, redis_client))
        
        if not groups_to_generate:
            logger.info("–í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–∂–µ –≤ –∫—ç—à–µ, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            return
        
        total_groups = len(groups_to_generate)
        logger.info(f"–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è {total_groups} –≥—Ä—É–ø–ø")
        print_progress_bar(0, total_groups, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", f"0/{total_groups} –≥—Ä—É–ø–ø")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
        completed = 0
        for i, (cache_key, week_schedule, week_name, group, redis_client) in enumerate(groups_to_generate):
            try:
                await generate_and_cache(cache_key, week_schedule, week_name, group, redis_client)
                completed += 1
                print_progress_bar(completed, total_groups, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", f"{completed}/{total_groups} –≥—Ä—É–ø–ø")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã {group}: {e}")
                print_progress_bar(completed, total_groups, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", f"{completed}/{total_groups} –≥—Ä—É–ø–ø (–æ—à–∏–±–∫–∞)")
        
        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {completed}/{total_groups} –≥—Ä—É–ø–ø")
    except Exception as e:
        logger.warning(f"warm_top_groups_images failed: {e}")

async def generate_full_schedule_images(user_data_manager: UserDataManager, timetable_manager: TimetableManager, redis_client: Redis):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –≥—Ä—É–ø–ø —Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é.
    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ 4 —É—Ç—Ä–∞ –≤ –Ω–æ—á—å —Å —Å—É–±–±–æ—Ç—ã –Ω–∞ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ.
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –æ–±–µ–∏—Ö –Ω–µ–¥–µ–ª—å (—á—ë—Ç–Ω–æ–π –∏ –Ω–µ—á—ë—Ç–Ω–æ–π).
    """
    try:
        logger.info("üîÑ –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–æ–ª–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –≥—Ä—É–ø–ø")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥—Ä—É–ø–ø—ã
        all_groups = list(timetable_manager._schedules.keys())
        if not all_groups:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥—Ä—É–ø–ø –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è")
            return
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        from core.config import MEDIA_PATH
        output_dir = MEDIA_PATH / "generated"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        successful = 0
        failed = 0
        total_size_mb = 0
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–ª—è –æ–±–µ–∏—Ö –Ω–µ–¥–µ–ª—å
        week_types = [
            ("odd", "–ù–µ—á—ë—Ç–Ω–∞—è –Ω–µ–¥–µ–ª—è"),
            ("even", "–ß—ë—Ç–Ω–∞—è –Ω–µ–¥–µ–ª—è")
        ]
        
        logger.info(f"üìä –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è {len(all_groups)} –≥—Ä—É–ø–ø, –æ–±–µ–∏—Ö –Ω–µ–¥–µ–ª—å")
        
        for week_key, week_name in week_types:
            logger.info(f"üìÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è {week_name}")
            
            for i, group in enumerate(all_groups, 1):
                try:
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø—ã
                    full_schedule = timetable_manager._schedules.get(group, {})
                    week_schedule = full_schedule.get(week_key, {})
                    
                    if not week_schedule:
                        logger.warning(f"‚ö†Ô∏è –ù–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –≥—Ä—É–ø–ø—ã {group} –Ω–∞ –Ω–µ–¥–µ–ª—é {week_key}")
                        failed += 1
                        continue
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                    cache_key = f"{group}_{week_key}"
                    output_path = output_dir / f"{cache_key}.png"
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    success = await generate_schedule_image(
                        schedule_data=week_schedule,
                        week_type=week_name,
                        group=group,
                        output_path=str(output_path)
                    )
                    
                    if success and os.path.exists(output_path):
                        successful += 1
                        file_size = os.path.getsize(output_path) / (1024 * 1024)  # –†–∞–∑–º–µ—Ä –≤ –ú–ë
                        total_size_mb += file_size
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à Redis
                        try:
                            with open(output_path, 'rb') as f:
                                image_bytes = f.read()
                            await redis_client.set(cache_key, image_bytes, ex=86400)  # –ö—ç—à –Ω–∞ 24 —á–∞—Å–∞
                            logger.info(f"‚úÖ {group} ({week_name}): –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ ({file_size:.2f} –ú–ë)")
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è {group} ({week_name}): –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫—ç—à: {e}")
                    else:
                        failed += 1
                        logger.error(f"‚ùå {group} ({week_name}): –æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                        
                except Exception as e:
                    failed += 1
                    logger.error(f"‚ùå {group} ({week_name}): –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info("=" * 60)
        logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ì–ï–ù–ï–†–ê–¶–ò–ò")
        logger.info("=" * 60)
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {successful} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        logger.info(f"‚ùå –û—à–∏–±–æ–∫: {failed} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        logger.info(f"üìÅ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size_mb:.2f} –ú–ë")
        if successful > 0:
            logger.info(f"üíæ –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {total_size_mb/successful:.2f} –ú–ë")
        logger.info("üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {e}")
        import traceback
        logger.error(traceback.format_exc())

async def monitor_schedule_changes(user_data_manager: UserDataManager, redis_client: Redis, bot: Bot):
    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏...")
    
    global global_timetable_manager_instance # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ–ø—Ä–∏—Å–≤–æ–µ–Ω–∏—è
    
    old_hash = (await redis_client.get(REDIS_SCHEDULE_HASH_KEY) or b'').decode()
    # Add retries
    attempts = 0
    while attempts < 3:
        try:
            new_schedule_data = await fetch_and_parse_all_schedules()
            break
        except Exception as e:
            attempts += 1
            logger.warning(f"Parse attempt {attempts} failed: {e}")
            if attempts == 3:
                logger.critical("Schedule parse failed after retries.")
                # Send alert
                from core.alert_sender import AlertSender
                async with AlertSender({}) as sender:
                    await sender.send({"severity": "critical", "summary": "Schedule parse failed"})
                return

    # For race condition: Use Redis lock
    async with redis_client.lock("timetable_manager_update_lock"):
        if new_schedule_data is None:
            logger.info("–î–∞–Ω–Ω—ã–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã (—É—Å–ª–æ–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å).")
            LAST_SCHEDULE_UPDATE_TS.set(_dt.now(MOSCOW_TZ).timestamp())
            return

        if not new_schedule_data:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Å —Å–µ—Ä–≤–µ—Ä–∞ –≤—É–∑–∞.")
            return
            
        new_hash = new_schedule_data.get('__current_xml_hash__')
        if new_hash != old_hash:
            # Detect changed groups
            changed_groups = []  # Compare schedules
            for group in changed_groups:
                users = await user_data_manager.get_users_by_group(group)
                for user in users:
                    send_message_task.send(user, "Schedule changed for your group!")
            logger.warning(f"–û–ë–ù–ê–†–£–ñ–ï–ù–´ –ò–ó–ú–ï–ù–ï–ù–ò–Ø –í –†–ê–°–ü–ò–°–ê–ù–ò–ò! –°—Ç–∞—Ä—ã–π —Ö–µ—à: {old_hash}, –ù–æ–≤—ã–π: {new_hash}")
            await redis_client.set(REDIS_SCHEDULE_HASH_KEY, new_hash)
            
            new_manager = TimetableManager(new_schedule_data, redis_client)
            await new_manager.save_to_cache()
            
            # –ü–µ—Ä–µ–ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
            global_timetable_manager_instance = new_manager
            
            # –ü—Ä–µ–¥–ø—Ä–æ–≥—Ä–µ–≤ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –ø–æ —Ç–æ–ø-–≥—Ä—É–ø–ø–∞–º (–≤ —Ñ–æ–Ω–µ)
            try:
                await warm_top_groups_images(user_data_manager, new_manager, redis_client)
            except Exception:
                pass
            
            all_users = await user_data_manager.get_all_user_ids()
            message_text = "‚ùóÔ∏è <b>–í–ù–ò–ú–ê–ù–ò–ï! –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è!</b>\n\n–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤ –±–æ—Ç–µ –±—ã–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Å–≤–æ–µ–π –≥—Ä—É–ø–ø—ã."
            for user_id in all_users:
                send_message_task.send(user_id, message_text)
                TASKS_SENT_TO_QUEUE.labels(actor_name='send_message_task').inc()
        else:
            logger.info("–ò–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")

    # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∫—É –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–∏ –ö–ê–ñ–î–û–ô —É—Å–ø–µ—à–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ
    LAST_SCHEDULE_UPDATE_TS.set(_dt.now(MOSCOW_TZ).timestamp())


# --- –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è ---
BACKUP_PREFIX = "timetable:backup:"

async def backup_current_schedule(redis_client: Redis):
    try:
        data = await redis_client.get(REDIS_SCHEDULE_HASH_KEY)
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º ¬´—Å–Ω–∞–ø—à–æ—Ç¬ª –∫–ª—é—á–∞ —Ö–µ—à–∞ –∏ –¥–∞–º–ø –¥–∞–Ω–Ω—ã—Ö –∫—ç—à–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
        from core.config import REDIS_SCHEDULE_CACHE_KEY
        cached_json = await redis_client.get(REDIS_SCHEDULE_CACHE_KEY)
        if cached_json:
            ts = _dt.now(MOSCOW_TZ).strftime('%Y%m%d_%H%M%S')
            await redis_client.set(f"{BACKUP_PREFIX}{ts}", cached_json)
            logger.info("–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: %s", ts)
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: %s", e)

async def collect_db_metrics(user_data_manager: UserDataManager):
    try:
        total_users = await user_data_manager.get_total_users_count()
        subscribed_users = await user_data_manager.get_subscribed_users_count()
        USERS_TOTAL.set(total_users)
        SUBSCRIBED_USERS.set(subscribed_users)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –º–µ—Ç—Ä–∏–∫ –∏–∑ –ë–î: {e}")

async def cleanup_image_cache(redis_client: Redis):
    try:
        cache = ImageCacheManager(redis_client, cache_ttl_hours=24)
        await cache.cleanup_expired_cache()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–ª–∞–Ω–æ–≤–æ–π –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")

async def generate_and_cache(cache_key: str, week_schedule: dict, week_name: str, group: str, redis_client: Redis):
    try:
        # –ü—É—Ç—å –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        from core.config import MEDIA_PATH
        output_dir = MEDIA_PATH / "generated"
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / f"{cache_key}.png"

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        ok = await generate_schedule_image(week_schedule, week_name.split(" ")[0], group, str(output_path))
        if ok and os.path.exists(output_path):
            with open(output_path, 'rb') as f:
                image_bytes = f.read()
            await redis_client.set(cache_key, image_bytes, ex=3600) # Cache for 1 hour
            logger.info(f"Image for {cache_key} generated and cached.")
        else:
            logger.warning(f"Image for {cache_key} generation failed or file not found.")
    except Exception as e:
        logger.warning(f"generate_and_cache failed for {cache_key}: {e}")

async def auto_backup(redis_client: Redis):
    # Backup DB (assume PostgreSQL)
    db_url = os.getenv("DATABASE_URL")
    backup_file = f"db_backup_{datetime.now().strftime('%Y%m%d')}.sql"
    os.system(f"pg_dump {db_url} > {backup_file}")
    
    # Backup schedules from Redis
    from core.config import REDIS_SCHEDULE_CACHE_KEY
    schedules = await redis_client.get(REDIS_SCHEDULE_CACHE_KEY)
    with open("schedules_backup.json", "w") as f:
        f.write(schedules.decode() if schedules else "{}")
    logger.info("Auto-backup completed.")

async def handle_graduated_groups(user_data_manager: UserDataManager, timetable_manager: TimetableManager, redis_client: Redis):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–∏—Ç—É–∞—Ü–∏–∏, –∫–æ–≥–¥–∞ –≥—Ä—É–ø–ø—ã –≤—ã–ø—É—Å—Ç–∏–ª–∏—Å—å –∏ –±–æ–ª—å—à–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏.
    –£–≤–µ–¥–æ–º–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤—ã–±—Ä–∞—Ç—å –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É.
    """
    try:
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä—è—é –Ω–∞–ª–∏—á–∏–µ –≤—ã–ø—É—Å—Ç–∏–≤—à–∏—Ö—Å—è –≥—Ä—É–ø–ø...")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∏—Ö –≥—Ä—É–ø–ø–∞–º–∏
        users_with_groups = await user_data_manager.get_all_users_with_groups()
        if not users_with_groups:
            logger.info("–ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –∏–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
        current_groups = set(timetable_manager._schedules.keys())
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–ª—é—á–∏
        current_groups = {g for g in current_groups if not g.startswith('__')}
        
        graduated_groups = set()
        affected_users = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        for user_id, group_name in users_with_groups:
            if group_name and group_name.upper() not in current_groups:
                graduated_groups.add(group_name.upper())
                affected_users.append((user_id, group_name))
        
        if not affected_users:
            logger.info("‚úÖ –í—Å–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∞–∫—Ç—É–∞–ª—å–Ω—ã")
            return
        
        logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤—ã–ø—É—Å—Ç–∏–≤—à–∏–µ—Å—è –≥—Ä—É–ø–ø—ã: {', '.join(graduated_groups)}")
        logger.info(f"üìä –ó–∞—Ç—Ä–æ–Ω—É—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(affected_users)}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥—Ä—É–ø–ø –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        available_groups = sorted(list(current_groups))
        
        # –£–≤–µ–¥–æ–º–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        bot = None
        try:
            from main import bot_instance
            bot = bot_instance
        except:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")
            return
        
        if not bot:
            logger.warning("–ë–æ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")
            return
        
        notified_count = 0
        for user_id, old_group in affected_users:
            try:
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                message_text = (
                    f"‚ö†Ô∏è <b>–í–Ω–∏–º–∞–Ω–∏–µ!</b>\n\n"
                    f"–ì—Ä—É–ø–ø–∞ <b>{old_group}</b> –±–æ–ª—å—à–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏.\n"
                    f"–í–æ–∑–º–æ–∂–Ω–æ, –≥—Ä—É–ø–ø–∞ –≤—ã–ø—É—Å—Ç–∏–ª–∞—Å—å –∏–ª–∏ –±—ã–ª–∞ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∞.\n\n"
                    f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É:\n"
                    f"<code>/start</code> - –¥–ª—è –≤—ã–±–æ—Ä–∞ –≥—Ä—É–ø–ø—ã\n\n"
                    f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –≥—Ä—É–ø–ø—ã: {', '.join(available_groups[:10])}"
                    + (f"\n... –∏ –µ—â–µ {len(available_groups) - 10} –≥—Ä—É–ø–ø" if len(available_groups) > 10 else "")
                )
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
                await bot.send_message(
                    chat_id=user_id,
                    text=message_text,
                    parse_mode="HTML"
                )
                
                # –û—á–∏—â–∞–µ–º –≥—Ä—É–ø–ø—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                await user_data_manager.set_user_group(user_id, None)
                
                notified_count += 1
                logger.info(f"‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –æ –≤—ã–ø—É—Å–∫–µ –≥—Ä—É–ø–ø—ã {old_group}")
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        
        logger.info(f"üìä –£–≤–µ–¥–æ–º–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {notified_count}/{len(affected_users)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ Redis –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        try:
            stats_key = "graduated_groups_stats"
            stats_data = {
                "timestamp": datetime.now(MOSCOW_TZ).isoformat(),
                "graduated_groups": list(graduated_groups),
                "affected_users": len(affected_users),
                "notified_users": notified_count
            }
            await redis_client.set(stats_key, json.dumps(stats_data, ensure_ascii=False), ex=86400)
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É: {e}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤—ã–ø—É—Å—Ç–∏–≤—à–∏—Ö—Å—è –≥—Ä—É–ø–ø: {e}")
        import traceback
        logger.error(traceback.format_exc())

def setup_scheduler(bot: Bot, manager: TimetableManager, user_data_manager: UserDataManager, redis_client: Redis) -> AsyncIOScheduler:
    scheduler = AsyncIOScheduler(timezone=str(MOSCOW_TZ))
    
    global global_timetable_manager_instance
    global_timetable_manager_instance = manager

    scheduler.add_job(evening_broadcast, 'cron', hour=20, minute=0, args=[user_data_manager, manager])
    scheduler.add_job(morning_summary_broadcast, 'cron', hour=8, minute=0, args=[user_data_manager, manager])
    scheduler.add_job(lesson_reminders_planner, 'cron', hour=6, minute=0, args=[scheduler, user_data_manager, manager])
    scheduler.add_job(monitor_schedule_changes, 'interval', minutes=CHECK_INTERVAL_MINUTES, args=[user_data_manager, redis_client, bot])
    scheduler.add_job(collect_db_metrics, 'interval', minutes=1, args=[user_data_manager]) 
    scheduler.add_job(backup_current_schedule, 'cron', hour='*/6', args=[redis_client])
    scheduler.add_job(auto_backup, 'cron', hour=2, args=[redis_client])
    scheduler.add_job(handle_graduated_groups, 'interval', minutes=10, args=[user_data_manager, manager, redis_client]) # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–ø—É—Å—Ç–∏–≤—à–∏—Ö—Å—è –≥—Ä—É–ø–ø
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é –≤ 4 —É—Ç—Ä–∞ –≤ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
    scheduler.add_job(generate_full_schedule_images, 'cron', day_of_week='sun', hour=4, minute=0, args=[user_data_manager, manager, redis_client])
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è –º–æ–∂–Ω–æ –≤–∫–ª—é—á–∞—Ç—å —á–µ—Ä–µ–∑ —Ñ–ª–∞–≥ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–∫–ª—é—á–µ–Ω—ã –¥–ª—è –æ–±–ª–µ–≥—á–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏ –∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ç–µ—Å—Ç–∞–º–∏)
    if os.getenv('ENABLE_IMAGE_CACHE_JOBS', '0') in ('1', 'true', 'True'):
        # –ï–∂–µ—á–∞—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –∫—ç—à–∞
        scheduler.add_job(cleanup_image_cache, 'cron', minute=5, args=[redis_client])
        # –ü—Ä–µ–¥–ø—Ä–æ–≥—Ä–µ–≤ –∫–∞—Ä—Ç–∏–Ω–æ–∫ —Ä–∞–∑ –≤ —Å—É—Ç–∫–∏ –Ω–æ—á—å—é
        scheduler.add_job(warm_top_groups_images, 'cron', hour=3, minute=15, args=[user_data_manager, manager, redis_client])
    
    return scheduler